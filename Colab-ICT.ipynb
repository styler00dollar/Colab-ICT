{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Colab-ICT.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqruwUfEPFwY"
      },
      "source": [
        "# Colab-ICT\n",
        "\n",
        "Original: [raywzy/ICT](https://github.com/raywzy/ICT)\n",
        "\n",
        "My fork: [styler00dollar/Colab-ICT](https://github.com/styler00dollar/Colab-ICT)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZ0wnjAfPMG9"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfQNjugiPJIV",
        "cellView": "form"
      },
      "source": [
        "#@title install\n",
        "!git clone https://github.com/raywzy/ICT\n",
        "%cd ICT\n",
        "!wget -O ckpts_ICT.zip https://www.dropbox.com/s/cqjgcj0serkbdxd/ckpts_ICT.zip?dl=1\n",
        "!unzip ckpts_ICT.zip\n",
        "!mkdir /content/input\n",
        "!mkdir /content/masks\n",
        "!mkdir -p /content/output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5OlUjInMP55",
        "cellView": "form"
      },
      "source": [
        "#@title Guided_Upsample/src/Guided_Upsampler.py (fixing with .cuda())\n",
        "%%writefile /content/ICT/Guided_Upsample/src/Guided_Upsampler.py\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from .dataset_my import Dataset\n",
        "from .models import  InpaintingModel\n",
        "from .utils import Progbar, create_dir, stitch_images, imsave\n",
        "from .metrics import PSNR\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "class Guided_Upsampler():\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "\n",
        "        if config.MODEL == 1:\n",
        "            model_name = 'edge'\n",
        "        elif config.MODEL == 2:\n",
        "            model_name = 'inpaint'\n",
        "\n",
        "        self.debug = False\n",
        "        self.model_name = model_name\n",
        "\n",
        "        self.inpaint_model = InpaintingModel(config).cuda()\n",
        "\n",
        "        self.psnr = PSNR(255.0).cuda()\n",
        "\n",
        "        # test mode\n",
        "        if self.config.MODE == 2:\n",
        "            self.test_dataset = Dataset(config, config.TEST_FLIST, config.TEST_EDGE_FLIST, config.TEST_MASK_FLIST, augment=False, training=False)\n",
        "        else:\n",
        "            self.train_dataset = Dataset(config, config.TRAIN_FLIST, config.TRAIN_EDGE_FLIST, config.TRAIN_MASK_FLIST, augment=True, training=True)\n",
        "            self.val_dataset = Dataset(config, config.VAL_FLIST, config.VAL_EDGE_FLIST, config.VAL_MASK_FLIST, augment=False, training=True)\n",
        "            self.sample_iterator = self.val_dataset.create_iterator(config.SAMPLE_SIZE)\n",
        "\n",
        "        self.samples_path = os.path.join(config.PATH, 'samples')\n",
        "        self.results_path = os.path.join(config.PATH, 'results')\n",
        "\n",
        "        if config.RESULTS is not None:\n",
        "            self.results_path = os.path.join(config.RESULTS)\n",
        "\n",
        "        if config.DEBUG is not None and config.DEBUG != 0:\n",
        "            self.debug = True\n",
        "\n",
        "        self.log_file = os.path.join(config.PATH, 'log_' + model_name + '.dat')\n",
        "\n",
        "    def load(self):\n",
        "\n",
        "        self.inpaint_model.load()\n",
        "        \n",
        "    def save(self):\n",
        "\n",
        "        self.inpaint_model.save()\n",
        "\n",
        "    def train(self):\n",
        "        train_loader = DataLoader(\n",
        "            dataset=self.train_dataset,\n",
        "            batch_size=self.config.BATCH_SIZE,\n",
        "            num_workers=4,\n",
        "            drop_last=True,\n",
        "            shuffle=True\n",
        "        )\n",
        "\n",
        "        epoch = 0\n",
        "        keep_training = True\n",
        "        model = self.config.MODEL\n",
        "        max_iteration = int(float((self.config.MAX_ITERS)))\n",
        "        total = len(self.train_dataset)\n",
        "\n",
        "        if total == 0:\n",
        "            print('No training data was provided! Check \\'TRAIN_FLIST\\' value in the configuration file.')\n",
        "            return\n",
        "\n",
        "        while(keep_training):\n",
        "            epoch += 1\n",
        "            print('\\n\\nTraining epoch: %d' % epoch)\n",
        "\n",
        "            if self.config.No_Bar:\n",
        "                pass\n",
        "            else:\n",
        "                progbar = Progbar(total, width=20, stateful_metrics=['epoch', 'iter'])\n",
        "\n",
        "            for items in train_loader:\n",
        "                self.inpaint_model.train()\n",
        "\n",
        "                images, edges, masks = self.cuda(*items)\n",
        "\n",
        "                # print(images.shape)\n",
        "                # print(edges.shape)\n",
        "                # print(masks.shape)\n",
        "\n",
        "                if model == 2:\n",
        "                    # train\n",
        "                    outputs, gen_loss, dis_loss, logs = self.inpaint_model.process(images, edges, masks)\n",
        "                    outputs_merged = (outputs * masks) + (images * (1 - masks))\n",
        "\n",
        "                    # metrics\n",
        "                    psnr = self.psnr(self.postprocess(images), self.postprocess(outputs_merged))\n",
        "                    mae = (torch.sum(torch.abs(images - outputs_merged)) / torch.sum(images)).float()\n",
        "                    logs.append(('psnr', psnr.item()))\n",
        "                    logs.append(('mae', mae.item()))\n",
        "\n",
        "                    # backward\n",
        "                    # self.inpaint_model.backward(gen_loss, dis_loss)\n",
        "                    iteration = self.inpaint_model.iteration\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                if iteration >= max_iteration:\n",
        "                    keep_training = False\n",
        "                    break\n",
        "\n",
        "                logs = [\n",
        "                    (\"epoch\", epoch),\n",
        "                    (\"iter\", iteration),\n",
        "                ] + logs\n",
        "\n",
        "                if self.config.No_Bar:\n",
        "                    pass\n",
        "                else:\n",
        "                    progbar.add(len(images), values=logs if self.config.VERBOSE else [x for x in logs if not x[0].startswith('l_')])\n",
        "\n",
        "                # log model at checkpoints\n",
        "                if self.config.LOG_INTERVAL and iteration % self.config.LOG_INTERVAL == 0:\n",
        "                    self.log(logs)\n",
        "\n",
        "                # sample model at checkpoints\n",
        "                if self.config.SAMPLE_INTERVAL and iteration % self.config.SAMPLE_INTERVAL == 0:\n",
        "                    self.sample()\n",
        "\n",
        "                # evaluate model at checkpoints\n",
        "                if self.config.EVAL_INTERVAL and iteration % self.config.EVAL_INTERVAL == 0:\n",
        "                    print('\\nstart eval...\\n')\n",
        "                    self.eval()\n",
        "\n",
        "                # save model at checkpoints\n",
        "                if self.config.SAVE_INTERVAL and iteration % self.config.SAVE_INTERVAL == 0:\n",
        "                    self.save()\n",
        "\n",
        "        print('\\nEnd training....')\n",
        "\n",
        "    def eval(self):\n",
        "        val_loader = DataLoader(\n",
        "            dataset=self.val_dataset,\n",
        "            batch_size=self.config.BATCH_SIZE,\n",
        "            drop_last=True,\n",
        "            shuffle=False\n",
        "        )\n",
        "\n",
        "        model = self.config.MODEL\n",
        "        total = len(self.val_dataset)\n",
        "\n",
        "        self.inpaint_model.eval()\n",
        "\n",
        "        if self.config.No_Bar:\n",
        "            pass\n",
        "        else:\n",
        "            progbar = Progbar(total, width=20, stateful_metrics=['it'])\n",
        "        iteration = 0\n",
        "\n",
        "        for items in val_loader:\n",
        "            iteration += 1\n",
        "            images, edges, masks = self.cuda(*items)\n",
        "\n",
        "\n",
        "\n",
        "            # inpaint model\n",
        "            if model == 2:\n",
        "                # eval\n",
        "                outputs, gen_loss, dis_loss, logs = self.inpaint_model.process(images, edges, masks)\n",
        "                outputs_merged = (outputs * masks) + (images * (1 - masks))\n",
        "\n",
        "                # metrics\n",
        "                psnr = self.psnr(self.postprocess(images), self.postprocess(outputs_merged))\n",
        "                mae = (torch.sum(torch.abs(images - outputs_merged)) / torch.sum(images)).float()\n",
        "                logs.append(('psnr', psnr.item()))\n",
        "                logs.append(('mae', mae.item()))\n",
        "\n",
        "\n",
        "            logs = [(\"it\", iteration), ] + logs\n",
        "            if self.config.No_Bar:\n",
        "                pass\n",
        "            else:\n",
        "                progbar.add(len(images), values=logs)\n",
        "\n",
        "    def test(self):\n",
        "\n",
        "        self.inpaint_model.eval()\n",
        "\n",
        "        model = self.config.MODEL\n",
        "        create_dir(self.results_path)\n",
        "\n",
        "        test_loader = DataLoader(\n",
        "            dataset=self.test_dataset,\n",
        "            batch_size=self.config.test_batch_size,\n",
        "        )\n",
        "\n",
        "        index = 0\n",
        "        for items in test_loader:\n",
        "\n",
        "            name = self.test_dataset.load_name(index)\n",
        "            \n",
        "            print(name)\n",
        "            \n",
        "            if self.config.same_face:\n",
        "                path = os.path.join(self.results_path, name)\n",
        "            else:\n",
        "                path = os.path.join(self.results_path, name[:-4]+\"_%d\"%(index%self.config.condition_num)+'.png')\n",
        "\n",
        "            images, edges, masks = self.cuda(*items)\n",
        "            index += self.config.test_batch_size\n",
        "\n",
        "            # inpaint model\n",
        "            if model == 2:\n",
        "                outputs = self.inpaint_model(images, edges, masks)\n",
        "                if self.config.merge:\n",
        "                    outputs_merged = (outputs * masks) + (images * (1 - masks))\n",
        "                else:\n",
        "                    outputs_merged = outputs\n",
        "\n",
        "            if self.config.same_face:\n",
        "                all_tensor=[images,edges,images * (1 - masks),outputs_merged]\n",
        "                all_tensor=torch.cat(all_tensor,dim=0)\n",
        "                vutils.save_image(all_tensor,path,nrow=self.config.test_batch_size,padding=0,normalize=False)\n",
        "                print(index, name)\n",
        "            else:\n",
        "                output = self.postprocess(outputs_merged)[0]\n",
        "                print(index, name)\n",
        "                imsave(output, path)\n",
        "\n",
        "            if self.debug:\n",
        "                edges = self.postprocess(1 - edges)[0]\n",
        "                masked = self.postprocess(images * (1 - masks) + masks)[0]\n",
        "                fname, fext = name.split('.')\n",
        "\n",
        "                imsave(edges, os.path.join(self.results_path, fname + '_edge.' + fext))\n",
        "                imsave(masked, os.path.join(self.results_path, fname + '_masked.' + fext))\n",
        "\n",
        "        print('\\nEnd test....')\n",
        "\n",
        "    def sample(self, it=None):\n",
        "        # do not sample when validation set is empty\n",
        "        if len(self.val_dataset) == 0:\n",
        "            return\n",
        "\n",
        "        self.inpaint_model.eval()\n",
        "\n",
        "        model = self.config.MODEL\n",
        "        items = next(self.sample_iterator)\n",
        "        images, edges, masks = self.cuda(*items)\n",
        "\n",
        "\n",
        "        # inpaint model\n",
        "        if model == 2:\n",
        "            iteration = self.inpaint_model.iteration\n",
        "            inputs = (images * (1 - masks)) + masks\n",
        "            outputs = self.inpaint_model(images, edges, masks)\n",
        "            outputs_merged = (outputs * masks) + (images * (1 - masks))\n",
        "\n",
        "        if it is not None:\n",
        "            iteration = it\n",
        "\n",
        "        image_per_row = 2\n",
        "        if self.config.SAMPLE_SIZE <= 6:\n",
        "            image_per_row = 1\n",
        "\n",
        "        images = stitch_images(\n",
        "            self.postprocess(images),\n",
        "            self.postprocess(inputs),\n",
        "            self.postprocess(edges),\n",
        "            self.postprocess(outputs),\n",
        "            self.postprocess(outputs_merged),\n",
        "            img_per_row = image_per_row\n",
        "        )\n",
        "\n",
        "\n",
        "        path = os.path.join(self.samples_path, self.model_name)\n",
        "        name = os.path.join(path, str(iteration).zfill(5) + \".png\")\n",
        "        create_dir(path)\n",
        "        print('\\nsaving sample ' + name)\n",
        "        images.save(name)\n",
        "\n",
        "    def log(self, logs):\n",
        "        with open(self.log_file, 'a') as f:\n",
        "            f.write('%s\\n' % ' '.join([str(item[1]) for item in logs]))\n",
        "\n",
        "    def cuda(self, *args):\n",
        "        return (item.to(self.config.DEVICE) for item in args)\n",
        "\n",
        "    def postprocess(self, img):\n",
        "        # [0, 1] => [0, 255]\n",
        "        img = img * 255.0\n",
        "        img = img.permute(0, 2, 3, 1)\n",
        "        return img.int()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OG2wzz3SN0WX",
        "cellView": "form"
      },
      "source": [
        "#@title Transformer/inference.py (removing broken import, replacing with glob)\n",
        "%%writefile /content/ICT/Transformer/inference.py\n",
        "## Inference\n",
        "\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import logging\n",
        "from utils.util import set_seed\n",
        "#from datas.dataset import ImageDataset\n",
        "from models.model import GPTConfig,GPT\n",
        "import argparse\n",
        "from utils.util import sample_mask,sample_mask_all\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import os\n",
        "import time\n",
        "\n",
        "import glob\n",
        "\n",
        "if __name__=='__main__':\n",
        "\n",
        "\n",
        "    parser=argparse.ArgumentParser()\n",
        "    parser.add_argument('--GPU_ids',type=str,default='0')\n",
        "    parser.add_argument('--ckpt_path',type=str,default='./ckpt')\n",
        "    parser.add_argument('--BERT',action='store_true', help='BERT model, Image Completion')\n",
        "    parser.add_argument('--image_url',type=str,default='',help='the folder of image')\n",
        "    parser.add_argument('--mask_url',type=str,default='',help='the folder of mask')\n",
        "    parser.add_argument('--top_k',type=int,default=100)\n",
        "\n",
        "    parser.add_argument('--image_size',type=int,default=32,help='input sequence length: image_size*image_size')\n",
        "\n",
        "    parser.add_argument('--n_layer',type=int,default=14)\n",
        "    parser.add_argument('--n_head',type=int,default=8)\n",
        "    parser.add_argument('--n_embd',type=int,default=256)\n",
        "    parser.add_argument('--GELU_2',action='store_true',help='use the new activation function')\n",
        "\n",
        "    parser.add_argument('--save_url',type=str,default='./',help='save the output results')\n",
        "    parser.add_argument('--n_samples',type=int,default=8,help='sample cnt')\n",
        "\n",
        "    parser.add_argument('--sample_all',action='store_true',help='sample all pixel together, ablation use')\n",
        "    parser.add_argument('--skip_number',type=int,default=0,help='since the inference is slow, skip the image which has been inferenced')\n",
        "\n",
        "    parser.add_argument('--no_progressive_bar',action='store_true',help='')\n",
        "    # parser.add_argument('--data_path',type=str,default='/home/ziyuwan/workspace/data/')\n",
        "\n",
        "    opts=parser.parse_args()\n",
        "\n",
        "    s_time=time.time()\n",
        "\n",
        "    # model_config=GPTConfig(512,32*32,\n",
        "    #                        embd_pdrop=0.0, resid_pdrop=0.0, \n",
        "    #                        attn_pdrop=0.0, n_layer=14, n_head=8,\n",
        "    #                        n_embd=256,BERT=opts.BERT)\n",
        "\n",
        "    model_config=GPTConfig(512,opts.image_size*opts.image_size,\n",
        "                           embd_pdrop=0.0, resid_pdrop=0.0, \n",
        "                           attn_pdrop=0.0, n_layer=opts.n_layer, n_head=opts.n_head,\n",
        "                           n_embd=opts.n_embd, BERT=opts.BERT, use_gelu2=opts.GELU_2)\n",
        "\n",
        "    # Load model\n",
        "    IGPT_model=GPT(model_config)\n",
        "    checkpoint=torch.load(opts.ckpt_path)\n",
        "    \n",
        "    if opts.ckpt_path.endswith('.pt'):\n",
        "        IGPT_model.load_state_dict(checkpoint)\n",
        "    else:\n",
        "        IGPT_model.load_state_dict(checkpoint['model'])\n",
        "\n",
        "    IGPT_model.cuda()\n",
        "\n",
        "    # Load clusters\n",
        "    C = np.load('kmeans_centers.npy') ## [0,1]\n",
        "    C = np.rint(127.5 * (C + 1.0))\n",
        "    C = torch.from_numpy(C)\n",
        "\n",
        "    n_samples=opts.n_samples\n",
        "\n",
        "    \"\"\"\n",
        "    img_list=sorted(os.listdir(opts.image_url))\n",
        "    mask_list=sorted(os.listdir(opts.mask_url))\n",
        "    \"\"\"\n",
        "    img_list = sorted(glob.glob(opts.image_url + '/**/*.png', recursive=True))\n",
        "    mask_list = sorted(glob.glob(opts.mask_url + '/**/*.png', recursive=True))\n",
        "\n",
        "\n",
        "    # mask_list=mask_list[-len(img_list):]\n",
        "    if opts.skip_number>0:\n",
        "        img_list=img_list[opts.skip_number-1:]\n",
        "        mask_list=mask_list[opts.skip_number-1:]\n",
        "        print(\"Resume from %s\"%(img_list[0]))\n",
        "\n",
        "\n",
        "    if opts.BERT:\n",
        "\n",
        "        for x_name,y_name in zip(img_list,mask_list):\n",
        "\n",
        "            if x_name!=y_name:\n",
        "                print(\"### Something Wrong ###\")\n",
        "\n",
        "            image_url=os.path.join(opts.image_url,x_name)\n",
        "            input_image=Image.open(image_url).convert(\"RGB\")\n",
        "            x = input_image.resize((opts.image_size,opts.image_size),resample=Image.BILINEAR)\n",
        "            x = torch.from_numpy(np.array(x)).view(-1, 3)\n",
        "            x = x.float()\n",
        "            a = ((x[:, None, :] - C[None, :, :])**2).sum(-1).argmin(1) # cluster assignments\n",
        "\n",
        "            mask_url=os.path.join(opts.mask_url,y_name)\n",
        "            input_mask=Image.open(mask_url).convert(\"L\")\n",
        "            y = input_mask.resize((opts.image_size,opts.image_size),resample=Image.NEAREST)\n",
        "            y = torch.from_numpy(np.array(y)/255.).view(-1)\n",
        "            y = y>0.5\n",
        "            y = y.float()\n",
        "\n",
        "            a_list=[a]*n_samples\n",
        "            a_tensor=torch.stack(a_list,dim=0) ## Input images\n",
        "            b_list=[y]*n_samples\n",
        "            b_tensor=torch.stack(b_list,dim=0) ## Input masks\n",
        "            a_tensor*=(1-b_tensor).long()\n",
        "\n",
        "            if opts.sample_all:\n",
        "                pixels=sample_mask_all(IGPT_model,context=a_tensor,length=opts.image_size*opts.image_size,num_sample=n_samples,top_k=opts.top_k,mask=b_tensor,no_bar=opts.no_progressive_bar)\n",
        "            else:\n",
        "                pixels=sample_mask(IGPT_model,context=a_tensor,length=opts.image_size*opts.image_size,num_sample=n_samples,top_k=opts.top_k,mask=b_tensor,no_bar=opts.no_progressive_bar)\n",
        "\n",
        "            img_name=x_name[:-4]+'.png'\n",
        "            for i in range(n_samples):\n",
        "\n",
        "                current_url=os.path.join(opts.save_url,'condition_%d'%(i+1))\n",
        "                os.makedirs(current_url,exist_ok=True)\n",
        "                current_img=C[pixels[i]].view(opts.image_size, opts.image_size, 3).numpy().astype(np.uint8)\n",
        "                tmp=Image.fromarray(current_img)\n",
        "\n",
        "                tmp.save(os.path.join(current_url,os.path.basename(img_name)))\n",
        "            print(\"Finish %s\"%(img_name))\n",
        "        \n",
        "        e_time=time.time()\n",
        "        print(\"This test totally costs %.5f seconds\"%(e_time-s_time))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diLONh6zM4Aq",
        "cellView": "form"
      },
      "source": [
        "#@title Guided_Upsample/src/models.py (fixing state_dict)\n",
        "%%writefile /content/ICT/Guided_Upsample/src/models.py\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from .networks import Discriminator, Discriminator2, InpaintGenerator_5\n",
        "from .loss import AdversarialLoss, PerceptualLoss, StyleLoss\n",
        "\n",
        "\n",
        "class BaseModel(nn.Module):\n",
        "    def __init__(self, name, config):\n",
        "        super(BaseModel, self).__init__()\n",
        "\n",
        "        self.name = name\n",
        "        self.config = config\n",
        "        self.iteration = 0\n",
        "\n",
        "        self.gen_weights_path = os.path.join(config.PATH, name + '_gen.pth')\n",
        "        self.dis_weights_path = os.path.join(config.PATH, name + '_dis.pth')\n",
        "\n",
        "    def load(self):\n",
        "        if os.path.exists(self.gen_weights_path):\n",
        "            print('Loading %s generator...' % self.name)\n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "                data = torch.load(self.gen_weights_path)\n",
        "            else:\n",
        "                data = torch.load(self.gen_weights_path, map_location=lambda storage, loc: storage)\n",
        "\n",
        "            #self.generator.load_state_dict(data['generator'])\n",
        "            self.generator.load_state_dict(data)\n",
        "            self.iteration = 0 # data['iteration']\n",
        "\n",
        "        # load discriminator only when training\n",
        "        if (self.config.MODE == 1 or self.config.score) and os.path.exists(self.dis_weights_path):\n",
        "            print('Loading %s discriminator...' % self.name)\n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "                data = torch.load(self.dis_weights_path)\n",
        "            else:\n",
        "                data = torch.load(self.dis_weights_path, map_location=lambda storage, loc: storage)\n",
        "\n",
        "            self.discriminator.load_state_dict(data['discriminator'])\n",
        "\n",
        "    def save(self):\n",
        "        print('\\nsaving %s...\\n' % self.name)\n",
        "        torch.save({\n",
        "            'iteration': self.iteration,\n",
        "            'generator': self.generator.state_dict()\n",
        "        }, self.gen_weights_path)\n",
        "\n",
        "        torch.save({\n",
        "            'discriminator': self.discriminator.state_dict()\n",
        "        }, self.dis_weights_path)\n",
        "\n",
        "\n",
        "class InpaintingModel(BaseModel):\n",
        "    def __init__(self, config):\n",
        "        super(InpaintingModel, self).__init__('InpaintingModel', config)\n",
        "\n",
        "        # generator input: [rgb(3) + edge(1)]\n",
        "        # discriminator input: [rgb(3)]\n",
        "        \n",
        "        if config.Generator==4:\n",
        "            print(\"*******remove IN*******\")\n",
        "            generator = InpaintGenerator_5()\n",
        "\n",
        "        if config.Discriminator==0:\n",
        "            discriminator = Discriminator(in_channels=3, use_sigmoid=config.GAN_LOSS != 'hinge')\n",
        "        else:\n",
        "            discriminator = Discriminator2(in_channels=3, use_sigmoid=config.GAN_LOSS != 'hinge')\n",
        "        \"\"\"\n",
        "        if len(config.GPU) > 1:\n",
        "            generator = nn.DataParallel(generator, config.GPU)\n",
        "            discriminator = nn.DataParallel(discriminator , config.GPU)\n",
        "        \"\"\"\n",
        "        l1_loss = nn.L1Loss()\n",
        "        perceptual_loss = PerceptualLoss()\n",
        "        style_loss = StyleLoss()\n",
        "        adversarial_loss = AdversarialLoss(type=config.GAN_LOSS)\n",
        "\n",
        "        self.add_module('generator', generator)\n",
        "        self.add_module('discriminator', discriminator)\n",
        "\n",
        "        self.add_module('l1_loss', l1_loss)\n",
        "        self.add_module('perceptual_loss', perceptual_loss)\n",
        "        self.add_module('style_loss', style_loss)\n",
        "        self.add_module('adversarial_loss', adversarial_loss)\n",
        "\n",
        "        self.gen_optimizer = optim.Adam(\n",
        "            params=generator.parameters(),\n",
        "            lr=float(config.LR),\n",
        "            betas=(config.BETA1, config.BETA2)\n",
        "        )\n",
        "\n",
        "        self.dis_optimizer = optim.Adam(\n",
        "            params=discriminator.parameters(),\n",
        "            lr=float(config.LR) * float(config.D2G_LR),\n",
        "            betas=(config.BETA1, config.BETA2)\n",
        "        )\n",
        "\n",
        "    def process(self, images, edges, masks):\n",
        "        self.iteration += 1\n",
        "\n",
        "        # zero optimizers\n",
        "        self.gen_optimizer.zero_grad()\n",
        "        self.dis_optimizer.zero_grad()\n",
        "\n",
        "\n",
        "        # process outputs\n",
        "        outputs = self(images, edges, masks)\n",
        "        gen_loss = 0\n",
        "        dis_loss = 0\n",
        "\n",
        "\n",
        "        # discriminator loss\n",
        "        dis_input_real = images\n",
        "        dis_input_fake = outputs.detach()\n",
        "        dis_real, _ = self.discriminator(dis_input_real)                    # in: [rgb(3)]\n",
        "        dis_fake, _ = self.discriminator(dis_input_fake)                    # in: [rgb(3)]\n",
        "        dis_real_loss = self.adversarial_loss(dis_real, True, True)\n",
        "        dis_fake_loss = self.adversarial_loss(dis_fake, False, True)\n",
        "        dis_loss += (dis_real_loss + dis_fake_loss) / 2\n",
        "\n",
        "        dis_loss.backward()\n",
        "        self.dis_optimizer.step()\n",
        "\n",
        "\n",
        "        # generator adversarial loss\n",
        "        gen_input_fake = outputs\n",
        "        gen_fake, _ = self.discriminator(gen_input_fake)                    # in: [rgb(3)]\n",
        "        gen_gan_loss = self.adversarial_loss(gen_fake, True, False) * self.config.INPAINT_ADV_LOSS_WEIGHT\n",
        "        gen_loss += gen_gan_loss\n",
        "\n",
        "\n",
        "        # generator l1 loss\n",
        "        gen_l1_loss = self.l1_loss(outputs, images) * self.config.L1_LOSS_WEIGHT / torch.mean(masks)\n",
        "        gen_loss += gen_l1_loss\n",
        "\n",
        "\n",
        "        # generator perceptual loss\n",
        "        gen_content_loss = self.perceptual_loss(outputs, images)\n",
        "        gen_content_loss = gen_content_loss * self.config.CONTENT_LOSS_WEIGHT\n",
        "        gen_loss += gen_content_loss\n",
        "\n",
        "\n",
        "        # generator style loss\n",
        "        gen_style_loss = self.style_loss(outputs * masks, images * masks)\n",
        "        gen_style_loss = gen_style_loss * self.config.STYLE_LOSS_WEIGHT\n",
        "        gen_loss += gen_style_loss\n",
        "\n",
        "\n",
        "        gen_loss.backward()\n",
        "        self.gen_optimizer.step()\n",
        "\n",
        "        # create logs\n",
        "        logs = [\n",
        "            (\"l_d2\", dis_loss.item()),\n",
        "            (\"l_g2\", gen_gan_loss.item()),\n",
        "            (\"l_l1\", gen_l1_loss.item()),\n",
        "            (\"l_per\", gen_content_loss.item()),\n",
        "            (\"l_sty\", gen_style_loss.item()),\n",
        "        ]\n",
        "\n",
        "        return outputs, gen_loss, dis_loss, logs\n",
        "\n",
        "    def forward(self, images, edges, masks):\n",
        "        images_masked = (images * (1 - masks).float()) + masks\n",
        "        inputs = torch.cat((images_masked, edges), dim=1)\n",
        "\n",
        "\n",
        "\n",
        "        if self.config.Generator==0 or self.config.Generator==2 or self.config.Generator==4:\n",
        "            outputs = self.generator(inputs)\n",
        "        else:\n",
        "            outputs = self.generator(inputs, masks)\n",
        "\n",
        "\n",
        "\n",
        "        if self.config.score:\n",
        "            gen_fake, _ =self.discriminator(outputs) \n",
        "            gen_fake=gen_fake.view(8,-1)\n",
        "            print(torch.mean(gen_fake,dim=1))\n",
        "\n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0riJG2kPCzB",
        "cellView": "form"
      },
      "source": [
        "#@title fixing imagenet state_dict\n",
        "# rfr paris\n",
        "%cd /content/\n",
        "\n",
        "#https://discuss.pytorch.org/t/dataparallel-changes-parameter-names-issue-with-load-state-dict/60211\n",
        "import torch\n",
        "from collections import OrderedDict\n",
        "state_dict = torch.load(\"/content/ICT/ckpts_ICT/Upsample/ImageNet/InpaintingModel_gen.pth\", map_location='cpu')\n",
        "new_state_dict = OrderedDict()\n",
        "\n",
        "for k, v in state_dict['generator'].items():\n",
        "  name = k.replace(\"module.\", \"\")\n",
        "\n",
        "  new_state_dict[name] = v\n",
        "\n",
        "torch.save(new_state_dict, '/content/ICT/ckpts_ICT/Upsample/ImageNet/InpaintingModel_gen.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rCaMq-cW6UW",
        "cellView": "form"
      },
      "source": [
        "#@title fixing places state_dict\n",
        "# rfr paris\n",
        "%cd /content/\n",
        "\n",
        "#https://discuss.pytorch.org/t/dataparallel-changes-parameter-names-issue-with-load-state-dict/60211\n",
        "import torch\n",
        "from collections import OrderedDict\n",
        "state_dict = torch.load(\"/content/ICT/ckpts_ICT/Upsample/Places2_Nature/InpaintingModel_gen.pth\", map_location='cpu')\n",
        "new_state_dict = OrderedDict()\n",
        "\n",
        "for k, v in state_dict['generator'].items():\n",
        "  name = k.replace(\"module.\", \"\")\n",
        "\n",
        "  new_state_dict[name] = v\n",
        "\n",
        "torch.save(new_state_dict, '/content/ICT/ckpts_ICT/Upsample/Places2_Nature/InpaintingModel_gen.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDp_7gwK7PP-"
      },
      "source": [
        "Paths\n",
        "```\n",
        "/content/input # user data\n",
        "/content/masks # user masks\n",
        "/content/output # results\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cn5bga-cuciS"
      },
      "source": [
        "# example data\n",
        "!wget \"https://i.guim.co.uk/img/media/6088d89032f8673c3473567a91157080840a7bb8/413_955_2808_1685/master/2808.jpg?width=1200&height=1200&quality=85&auto=format&fit=crop&s=412cc526a799b2d3fff991129cb8f030\" -O /content/input/0.png\n",
        "!wget \"https://i.stack.imgur.com/PIfn1.png\" -O /content/masks/0.png"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vf1dEXDpRogv"
      },
      "source": [
        "# resize, input must be 256px\n",
        "import cv2\n",
        "image = cv2.imread(\"/content/input/0.png\")\n",
        "image = cv2.resize(image, (256,256), interpolation=cv2.INTER_NEAREST)\n",
        "cv2.imwrite(\"/content/input/0.png\", image)\n",
        "\n",
        "image = cv2.imread(\"/content/masks/0.png\")\n",
        "image = cv2.resize(image, (256,256), interpolation=cv2.INTER_NEAREST)\n",
        "cv2.imwrite(\"/content/masks/0.png\", image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eytuT7x5iaT"
      },
      "source": [
        "# running with places\n",
        "%cd /content/ICT/Transformer\n",
        "!python inference.py --ckpt_path /content/ICT/ckpts_ICT/Transformer/Places2_Nature.pth \\\n",
        "                                --BERT --image_url \"/content/input\" \\\n",
        "                                --mask_url \"/content/masks\" \\\n",
        "                                --n_layer 35 --n_embd 512 --n_head 8 --top_k 40 --GELU_2 \\\n",
        "                                --save_url \"/content/prior\" \\\n",
        "                                --image_size 32 --n_samples 1\n",
        "\n",
        "%cd /content/ICT/Guided_Upsample\n",
        "!python test.py --input \"/content/input/\" \\\n",
        "                                        --mask \"/content/masks\" \\\n",
        "                                        --prior \"/content/prior\" \\\n",
        "                                        --output \"/content/output\" \\\n",
        "                                        --checkpoints /content/ICT/ckpts_ICT/Upsample/Places2_Nature \\\n",
        "                                        --test_batch_size 1 --model 2 --Generator 4 --condition_num 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaJ2W6-LP1hQ"
      },
      "source": [
        "# delete output files if needed, folder must be empty for a run\n",
        "%cd /content\n",
        "!sudo rm -rf /content/output\n",
        "!mkdir /content/output\n",
        "!sudo rm -rf /content/prior\n",
        "!mkdir /content/prior"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
